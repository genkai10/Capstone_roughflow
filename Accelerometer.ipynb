{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-mjmk5i-lsS",
        "outputId": "3cba910b-9385-4878-c2f8-5ce63ae6ce79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tsfresh"
      ],
      "metadata": {
        "id": "82MoncaI7na_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boruta"
      ],
      "metadata": {
        "id": "zG_NSKnkFIOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import all libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
        "from tsfresh import select_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "plwlS6Nm-tkN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory paths for fall and ADL sequences\n",
        "fall_dir = '/content/drive/MyDrive/Capstone/AccelerometerData/Fall'\n",
        "adl_dir = '/content/drive/MyDrive/Capstone/AccelerometerData/ADL'\n",
        "\n",
        "# Function to load CSV files and return a list of dataframes\n",
        "def load_csv_data(directory,classification):\n",
        "    data = []\n",
        "    for file_name in os.listdir(directory):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(directory, file_name)\n",
        "            # Specify column names explicitly\n",
        "            df = pd.read_csv(file_path, header=None, names=['time', 'SV_total', 'Ax', 'Ay', 'Az'])\n",
        "            df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
        "            df['classification'] = classification\n",
        "            data.append(df)\n",
        "    return data\n",
        "\n",
        "# Load CSV files for fall and ADL sequences\n",
        "fall_data = load_csv_data(fall_dir,0)\n",
        "adl_data = load_csv_data(adl_dir,1)\n",
        "\n",
        "combined_data = fall_data + adl_data"
      ],
      "metadata": {
        "id": "-9Ru83YUoQLB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sequence_id(df, sequence_id):\n",
        "    df['sequence_id'] = sequence_id\n",
        "    return df\n",
        "\n",
        "time_series = [add_sequence_id(df, sequence_id=i) for i, df in enumerate(combined_data)]\n"
      ],
      "metadata": {
        "id": "kft6OCYNLlja"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series"
      ],
      "metadata": {
        "id": "hZ1FeBAcsO7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tsfresh_features(ts_df):\n",
        "    print(ts_df.head())\n",
        "    features = extract_features(ts_df, column_id=\"sequence_id\", column_sort=\"time\")\n",
        "    return features\n",
        "\n",
        "features = pd.concat([extract_tsfresh_features(df) for df in time_series])"
      ],
      "metadata": {
        "id": "QhABStgGT10c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "5qFtr-ekfi2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.Series([df['classification'][0] for df in time_series])\n",
        "\n",
        "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "impute(features)\n",
        "features_filtered = select_features(features, y)"
      ],
      "metadata": {
        "id": "diWvc4pJfzuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_filtered"
      ],
      "metadata": {
        "id": "M51bWatyzG20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "# Calculate mutual information scores\n",
        "mi_scores = mutual_info_classif(features_filtered, y)\n",
        "\n",
        "# Select top 500 features based on mutual information scores\n",
        "k_best = SelectKBest(mutual_info_classif, k=500)\n",
        "selected_features = k_best.fit_transform(features_filtered, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_indices = k_best.get_support(indices=True)\n",
        "\n",
        "# Filter the original features dataframe to keep only the selected features\n",
        "selected_features_df = features_filtered.iloc[:, selected_indices]\n"
      ],
      "metadata": {
        "id": "o49roRS-8nN7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_df"
      ],
      "metadata": {
        "id": "UQiJsznLHddl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Remove Highly Correlated Features Using Pearson Correlation Coefficient\n",
        "def remove_highly_correlated_features(features_df, threshold=0.85):\n",
        "    corr_matrix = features_df.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    features_df_filtered = features_df.drop(columns=to_drop)\n",
        "    return features_df_filtered\n",
        "\n",
        "def apply_boruta(features_df, y):\n",
        "    # Initialize Random Forest classifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    boruta_selector = BorutaPy(rf, n_estimators=100, verbose=2, random_state=42)\n",
        "    boruta_selector.fit(features_df.values, y.values)\n",
        "    selected_features = features_df.columns[boruta_selector.support_].tolist()\n",
        "    return features_df[selected_features]\n",
        "\n",
        "\n",
        "# Step 3: Selection of Top Features Using Feature Importance\n",
        "def select_top_features(features_df, y, n_top_features=5):\n",
        "    selector = SelectKBest(score_func=f_classif, k=n_top_features)\n",
        "    selector.fit(features_df, y)\n",
        "    selected_indices = selector.get_support(indices=True)\n",
        "    selected_features = features_df.columns[selected_indices].tolist()\n",
        "    return features_df[selected_features]\n",
        "\n",
        "# Assuming features_df is your DataFrame containing all the features and y is your target variable\n",
        "\n",
        "# Step 1: Remove Highly Correlated Features\n",
        "features_df_filtered = remove_highly_correlated_features(selected_features_df)\n",
        "\n",
        "# Step 2: Boruta Algorithm\n",
        "#boruta_features = apply_boruta(features_df_filtered, y)\n",
        "\n",
        "# Step 3: Selection of Top Features Using Feature Importance\n",
        "top_features = select_top_features(features_df_filtered, y, n_top_features=10)\n"
      ],
      "metadata": {
        "id": "nRm0Mt-8JXh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_features"
      ],
      "metadata": {
        "id": "2MchsOdKLFRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = top_features\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Step 3: Train an ML classifier\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Step 4: Evaluate the classifier\n",
        "# y_pred = rf_classifier.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(\"Accuracy:\", accuracy)\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Prepare the data\n",
        "# Assuming top_features contains the selected features and y is the target variable\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(top_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the classifier\n",
        "# Choose either RandomForestClassifier or GaussianNB\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# classifier = GaussianNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the classifier\n",
        "# Option 1: Evaluate using accuracy on the testing set\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Option 2: Perform k-fold cross-validation to get average accuracy\n",
        "# k = 3 (as mentioned)\n",
        "cv_scores = cross_val_score(classifier, top_features, y, cv=3)\n",
        "average_accuracy = cv_scores.mean()\n",
        "print(\"Average accuracy (k-fold cross-validation):\", average_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhTqPJj-hqUz",
        "outputId": "471c5986-8fcc-49d5-a33d-ddfb83608457"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Average accuracy (k-fold cross-validation): 0.9710144927536232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Txwdp52Mltx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}